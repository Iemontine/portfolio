<div class="terminal-text">
  <h1>$ ls research/</h1>

  <div class="cards">
    <article class="card clickable pond" role="link" tabindex="0" data-url="https://github.com/UCD-193AB-ws24/Minecapstone">
      <header class="card-head">
        <div class="card-kicker">Senior Design â€” UC Davis</div>
        <h2 class="card-title">Simulated Profiling Environment for Embodied Intelligence (SPEEN)</h2>
        <div class="card-meta">Spring 2025</div>
      </header>
      <div class="card-body">
        <p>SPEEN is a prototype environment for evaluating LLM-based agentic AI inside a physically simulated world, focusing on embodied interaction, visual modality, and sequential reasoning. I led agent control, environment generation, navigation, test scenarios, and prompt/control interfaces.</p>
        <ul>
          <li>Shifted mid-project toward rigorous evaluation axes for Embodied AI.</li>
          <li>Built procedural worlds, agent-environment tooling, and analysis harnesses.</li>
        </ul>
      </div>
    </article>

  <article class="card clickable pond" role="link" tabindex="0" data-url="https://github.com/Iemontine/AudioVideoDescriptiveAI">
      <header class="card-head">
        <div class="card-kicker">Applied ML</div>
        <h2 class="card-title">Context Embedding for Enhanced Video Description by LLM</h2>
        <div class="card-meta">Summer 2024</div>
      </header>
      <div class="card-body">
        <p>Project lead on a hacky-but-effective approach to restore temporal/audio context to a vision-only LLM by embedding per-frame cues derived from audio classification (PANNs). Produced narrated recap videos; surfaced limits in multimodal prompting and multi-label audio tagging.</p>
        <ul>
          <li>Authored methodology and analysis; identified dataset noise and hallucination modes.</li>
          <li>Explored fine-tuning/prompting directions for future reliability.</li>
        </ul>
      </div>
    </article>

  <article class="card clickable pond" role="link" tabindex="0" data-url="https://github.com/Iemontine/SonicGameplayingAI">
      <header class="card-head">
        <div class="card-kicker">Reinforcement Learning</div>
        <h2 class="card-title">Gameplaying AI with Proximal Policy Optimization</h2>
        <div class="card-meta">Spring 2024</div>
      </header>
      <div class="card-body">
        <p>Self-led reimplementation of PPO applied to Sonic the Hedgehog (Genesis). Built the training environment, tuned hyperparameters, and analyzed learning dynamics; reached consistent level clears with ~2 hours of training.</p>
        <ul>
          <li>Emphasis on data richness and tuning over hand-crafted curriculum.</li>
        </ul>
      </div>
    </article>
  </div>
</div>
